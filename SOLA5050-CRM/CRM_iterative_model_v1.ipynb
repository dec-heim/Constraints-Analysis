{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congestion Relief Market - Iterative Solution\n",
    "#### Jupyter Notebook developed by Declan Heim for SOLA5050 Assignment T1 2022.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Foreword\n",
    "A brief context is provided here as abstracted from the accompanying report. This main script is used to preform the iteration solution for the CRM model in nempy.\n",
    "\n",
    "### Research Question\n",
    "How would the proposed Edify Energy’s Congestion Relief Market (CRM) affect the spot market profitability of Utility-PV generators in the NEM which are frequently involved in binding thermal constraints? \n",
    "\n",
    "### Case Study\n",
    "The question is addressed through a defined case study. This case assesses historical data from the 15th of February 2021 in which considerable Utility-PV generation was curtailed in the Central-West Orana region of NSW, as reported by various sources (AEMO, 2021c; Simpson, 2021).\n",
    "\n",
    "Specifically, the following parameters are defined in this case study:\n",
    "- Simulation Period – historical dispatch interval data that is considered for simulation is confined to the 15th of February, 2021.\n",
    "- Selected constraints – the considered thermal binding constraint equations for which the CRM is considered include:\n",
    "    - Line 94T constraints: N>>N_NIL_94T, N>>N_NIL_94T_947.\n",
    "    - Line 94K constraints: N>>N-PKWL_94K_1, N>>N-PKWL_94K_2, N>>N-PKWL_94K_3.\n",
    "- Eligible Units – those units identifiable on the LHS of the selected constraints. These units are presented prior in Figure 2 and mapped to the respective constraints in the results section. Note that while Bodangora Wind Farm contributes to these constraints and is included in modelling, it has been omitted from the presented analysis given the focus here on utility-PV curtailment.\n",
    "\n",
    "Note: \n",
    "1. Line 94K constraints have not been modelled but included for context with specific extracts in the appendix. \n",
    "2. A description of the constraint names is appended to the report as obtained from NEOmobile (Intelligent Energy Systems, 2022).\n",
    "\n",
    "### Data\n",
    "#### Input Data to the Model\n",
    "This counter-factual data model requires extensive historical NEM data obtained from AEMO’s Market Management System (MMS) which is published to NEMWEB (AEMO, 2022b). Various data sources obtained from MMS are configured as inputs to the ‘nempy’ simulator. Given these inputs are configured by the simulation package, details of each AEMO dataset are omitted, however these are noted in an example simulation of nempy (Gorman, 2022) as well as accessible via the appended source-code. \n",
    "#### Output Data retrieved from the Model\n",
    "By solving the economic dispatch model, nempy is able to provide market outcomes including prices, individual unit dispatch volumes, and information on binding constraints. Of the three key outcomes noted, market prices should remain unchanged before and after the CRM, unit dispatch volumes change in accordance with the CRM outcomes and finally non-zero marginal values  reflect where a specific constraint is bound.\n",
    "\n",
    "### Method\n",
    "#### High-level Overview\n",
    "1. Using the case study parameters, an initial ‘base case’ energy dispatch simulation for a specific dispatch interval is performed in nempy. This yields the results of the historical market conditions.\n",
    "\n",
    "    a. From the base case, it is verified that the ‘selected constraints’ are binding and units which are involved in the LHS of the constraint are identified. Only these units will be eligible to participate in a CRM associated with this constraint.\n",
    "    \n",
    "    \n",
    "2.\tA second iteration of the dispatch simulation is performed with the selected constraints entirely removed, establishing a ‘removed-constraint case’.\n",
    "\n",
    "    a.\tFrom this case, the impact that the selected constraint has on each unit is identified by the difference in dispatch between the ‘base case’ and ‘removed-constraint case’. This difference, typically an increase in dispatch volume in MWs, provides a maximum volume for congestion relief that can be bought by the respective unit for the associated CRM.\n",
    "    \n",
    "    \n",
    "3.\tA simple dispatch model of the associated CRM is created for the ‘selected constraints’ and solved. The structure would follow the example on page 6 of Edify’s submission (Stiel, 2021).\n",
    "\n",
    "    a.\tOnly eligible participants bids are modelled – step I.a. above.\n",
    "    \n",
    "    b.\tOne congestion relief provider, a hypothetical utility-BESS, is created by adding this unit to the CRM.\n",
    "    \n",
    "    c.\tThe offer/bid price that each participant submits to CRM is predefined hypothetically.\n",
    "    \n",
    "    d.\tA maximum cap is imposed on the amount of congestion relief bought, step II.a., and the price at which the congestion relief market can settle, being no greater than the energy price. \n",
    "    \n",
    "    \n",
    "4.\tHaving solved the CRM associated with the selected constraint, generic constraints are written into the nempy model to define the CRM preference for dispatch so that the congestion relief providers and buyers are dispatched in accordance with the CRM outputs.\n",
    "\n",
    "\n",
    "5.\tA third and final iteration of the energy dispatch simulation is performed given the considerations of step IV, and the addition of the hypothetical storage unit into the market.\n",
    "\n",
    "\n",
    "6.\tThe results from the above procedure are collated from python, with the various output datasets visualized in Tableau. Repetitions of the above with variations to the CRM offer/bid prices can be considered as differing scenarios. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"Home\"></a>\n",
    "## Model Implementation\n",
    "\n",
    "### Notebook Contents\n",
    "- [Section A: Model Building](#A)\n",
    "- [Section B: Iterative Solution](#B)\n",
    "- [Section C: Aggregating Results](#C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"A\"></a>\n",
    "\n",
    "---\n",
    "\n",
    "## Section A: Model Building\n",
    "### A1. Import Python Packages + Configure Result File Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Standard Packages\n",
    "import pandas as pd\n",
    "!pip install db-sqlite3\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# The forked nempy market dispatch engine is loaded with additional constraints features\n",
    "!pip install --user --upgrade git+https://github.com/dec-heim/nempy_constraints_v1.git\n",
    "from nempy import markets, time_sequential\n",
    "from nempy.historical_inputs import loaders, mms_db, \\\n",
    "    xml_cache, units, demand, interconnectors, constraints\n",
    "\n",
    "# Helper Functions\n",
    "from crm_helper_functions import *\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Structure is defined, customising the folder name per simulation run\n",
    "folder_name = 'simulation_number_01'\n",
    "fld_parent = os.path.join('results',folder_name)\n",
    "\n",
    "fld_mv = os.path.join('results',folder_name,'marginal_values')\n",
    "fld_ud = os.path.join('results',folder_name,'unit_dispatch')\n",
    "fld_ep = os.path.join('results',folder_name,'energy_prices')\n",
    "fld_erev = os.path.join('results',folder_name,'energy_revenue')\n",
    "fld_err = os.path.join('results',folder_name,'error')\n",
    "fld_dd = os.path.join('results',folder_name,'dispatch_diff')\n",
    "fld_cp = os.path.join('results',folder_name,'crm_prices')\n",
    "fld_cd = os.path.join('results',folder_name,'crm_dispatch')\n",
    "fld_cr = os.path.join('results',folder_name,'crm_revenue')\n",
    "\n",
    "if not os.path.exists(os.path.join('results',folder_name)):\n",
    "    os.makedirs(fld_mv)\n",
    "    os.makedirs(fld_ud)\n",
    "    os.makedirs(fld_ep)\n",
    "    os.makedirs(fld_erev)\n",
    "    os.makedirs(fld_err)\n",
    "    os.makedirs(fld_dd)\n",
    "    os.makedirs(fld_cp)\n",
    "    os.makedirs(fld_cd)\n",
    "    os.makedirs(fld_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### A2. Retrieve + Prepare Historical Data from AEMO\n",
    "\n",
    "The data for this example has already been extracted and prepared for nempy locally. The data was found for the **15th February 2021** and includes a range of parameters, to name a few:\n",
    "- unit details\n",
    "- unit availability\n",
    "- volume bids\n",
    "- price bids\n",
    "- unit ramp rate constraints\n",
    "- interconnector models with loss equations\n",
    "- regional demand constraints\n",
    "- various other constraints such as FCAS, generic constraint sets\n",
    "\n",
    "Further steps on how to download the data from AEMO MMS and configure this for nempy are provided in the [Detailed Recreation of Historical Dispatch Example](https://nempy.readthedocs.io/en/latest/examples.html#detailed-recreation-of-historical-dispatch) within nempy documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('feb_2021_mms.db')\n",
    "mms_db_manager = mms_db.DBManager(connection=con)\n",
    "xml_cache_manager = xml_cache.XMLCacheManager('feb_2021_cache')\n",
    "\n",
    "raw_inputs_loader = loaders.RawInputsLoader(\n",
    "    nemde_xml_cache_manager=xml_cache_manager,\n",
    "    market_management_system_database=mms_db_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### A3. Define Dispatch Intervals\n",
    "For this specific example, we create dispatch intervals for **15th February 2021 from 6am to 7pm** to capture periods of utility-PV generation. This is formatted as a list for ease of later assessing multiple intervals.\n",
    "\n",
    "Once the intervals are defined, the subsequent functions are called to load the respective data from our previously downloaded database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_intervals = create_dispatch_list('2021/02/15 06:00:00','2021/02/15 19:00:00')\n",
    "di_df = pd.DataFrame(dispatch_intervals, columns=['di_list'])\n",
    "di_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### A4. Define the NEM Energy Market Model\n",
    "The subsequent data loaded into the nempy market object follows the [Detailed Recreation of Historical Dispatch](https://nempy.readthedocs.io/en/latest/examples.html#detailed-recreation-of-historical-dispatch) so we will omit this detail here for brevity and highlight only the generic constraints which are of interest in this analysis.\n",
    "\n",
    "The <code>select_constraint</code> variable is used to define which constraints we analyse and hence which market the CRM is modelled for.\n",
    "Equivalently, the <code>model_region</code> is defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_constraint = ['N>>N-NIL_94T_947']\n",
    "model_region = 'NSW1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_market(raw_inputs_loader, interval, add_relief_provider, relief):\n",
    "     \n",
    "    raw_inputs_loader.set_interval(interval)\n",
    "    unit_inputs = units.UnitData(raw_inputs_loader)\n",
    "    interconnector_inputs = interconnectors.InterconnectorData(raw_inputs_loader)\n",
    "    constraint_inputs = constraints.ConstraintData(raw_inputs_loader)\n",
    "    demand_inputs = demand.DemandData(raw_inputs_loader)\n",
    "\n",
    "    # Define market, unit info\n",
    "    unit_info = unit_inputs.get_unit_info()\n",
    "    if add_relief_provider:\n",
    "        unit_info = append_rp_unitinfo(unit_info, relief['new_storage'])\n",
    "    market = markets.SpotMarket(market_regions=['QLD1', 'NSW1', 'VIC1',\n",
    "                                                'SA1', 'TAS1'],\n",
    "                                unit_info=unit_info)\n",
    "\n",
    "    # Set volume, price bids\n",
    "    volume_bids, price_bids = unit_inputs.get_processed_bids()\n",
    "    if add_relief_provider:\n",
    "        volume_bids = append_rp_volumebids(volume_bids, relief['new_storage'])\n",
    "        price_bids = append_rp_pricebids(price_bids, relief['new_storage'])\n",
    "    market.set_unit_volume_bids(volume_bids)\n",
    "    market.set_unit_price_bids(price_bids)\n",
    "    \n",
    "    # Set bid in capacity limits\n",
    "    unit_bid_limit = unit_inputs.get_unit_bid_availability()\n",
    "    market.set_unit_bid_capacity_constraints(unit_bid_limit)\n",
    "    cost = constraint_inputs.get_constraint_violation_prices()['unit_capacity']\n",
    "    market.make_constraints_elastic('unit_bid_capacity', violation_cost=cost)\n",
    "\n",
    "    # Set limits provided by the unconstrained intermittent generation\n",
    "    # forecasts. Primarily for wind and solar.\n",
    "    unit_uigf_limit = unit_inputs.get_unit_uigf_limits()\n",
    "    market.set_unconstrained_intermitent_generation_forecast_constraint(\n",
    "        unit_uigf_limit)\n",
    "    cost = constraint_inputs.get_constraint_violation_prices()['uigf']\n",
    "    market.make_constraints_elastic('uigf_capacity', violation_cost=cost)\n",
    "\n",
    "    # Set unit ramp rates.\n",
    "    ramp_rates = unit_inputs.get_ramp_rates_used_for_energy_dispatch()\n",
    "    market.set_unit_ramp_up_constraints(\n",
    "        ramp_rates.loc[:, ['unit', 'initial_output', 'ramp_up_rate']])\n",
    "    market.set_unit_ramp_down_constraints(\n",
    "        ramp_rates.loc[:, ['unit', 'initial_output', 'ramp_down_rate']])\n",
    "    cost = constraint_inputs.get_constraint_violation_prices()['ramp_rate']\n",
    "    market.make_constraints_elastic('ramp_up', violation_cost=cost)\n",
    "    market.make_constraints_elastic('ramp_down', violation_cost=cost)\n",
    "\n",
    "    # Set unit FCAS trapezium constraints.\n",
    "    unit_inputs.add_fcas_trapezium_constraints()\n",
    "    cost = constraint_inputs.get_constraint_violation_prices()['fcas_max_avail']\n",
    "    fcas_availability = unit_inputs.get_fcas_max_availability()\n",
    "    market.set_fcas_max_availability(fcas_availability)\n",
    "    market.make_constraints_elastic('fcas_max_availability', cost)\n",
    "    cost = constraint_inputs.get_constraint_violation_prices()['fcas_profile']\n",
    "    regulation_trapeziums = unit_inputs.get_fcas_regulation_trapeziums()\n",
    "    market.set_energy_and_regulation_capacity_constraints(regulation_trapeziums)\n",
    "    market.make_constraints_elastic('energy_and_regulation_capacity', cost)\n",
    "    scada_ramp_down_rates = unit_inputs.get_scada_ramp_down_rates_of_lower_reg_units()\n",
    "    market.set_joint_ramping_constraints_lower_reg(scada_ramp_down_rates)\n",
    "    market.make_constraints_elastic('joint_ramping_lower_reg', cost)\n",
    "    scada_ramp_up_rates = unit_inputs.get_scada_ramp_up_rates_of_raise_reg_units()\n",
    "    market.set_joint_ramping_constraints_raise_reg(scada_ramp_up_rates)\n",
    "    market.make_constraints_elastic('joint_ramping_raise_reg', cost)\n",
    "    contingency_trapeziums = unit_inputs.get_contingency_services()\n",
    "    market.set_joint_capacity_constraints(contingency_trapeziums)\n",
    "    market.make_constraints_elastic('joint_capacity', cost)\n",
    "\n",
    "    # Set interconnector definitions, limits and loss models.\n",
    "    interconnectors_definitions = \\\n",
    "        interconnector_inputs.get_interconnector_definitions()\n",
    "    loss_functions, interpolation_break_points = \\\n",
    "        interconnector_inputs.get_interconnector_loss_model()\n",
    "    market.set_interconnectors(interconnectors_definitions)\n",
    "    market.set_interconnector_losses(loss_functions,\n",
    "                                      interpolation_break_points)\n",
    "\n",
    "    # Add FCAS market constraints.\n",
    "    fcas_requirements = constraint_inputs.get_fcas_requirements()\n",
    "    market.set_fcas_requirements_constraints(fcas_requirements)\n",
    "    violation_costs = constraint_inputs.get_violation_costs()\n",
    "    market.make_constraints_elastic('fcas', violation_cost=violation_costs) \n",
    "\n",
    "    # Add generic constraints, RHS parameters\n",
    "    generic_rhs = constraint_inputs.get_rhs_and_type_excluding_regional_fcas_constraints()\n",
    "    if add_relief_provider:\n",
    "        generic_rhs = append_rbuy_rhs(generic_rhs, relief['crm_buyers'])\n",
    "        violation_costs = append_rbuy_violationcosts(violation_costs, relief['crm_buyers'])\n",
    "        generic_rhs = append_rbuy_rhs(generic_rhs, relief['crm_provider_rhs'])\n",
    "        violation_costs = append_rbuy_violationcosts(violation_costs, relief['crm_provider_rhs'])\n",
    "        \n",
    "    market.set_generic_constraints(generic_rhs)\n",
    "    market.make_constraints_elastic('generic', violation_cost=violation_costs)\n",
    "    \n",
    "    # Add generic constraints, LHS coefficients DUIDs\n",
    "    unit_generic_lhs = constraint_inputs.get_unit_lhs()\n",
    "    if add_relief_provider:\n",
    "        unit_generic_lhs = append_rp_lhs(unit_generic_lhs, relief['new_storage'])\n",
    "        unit_generic_lhs = append_rbuy_lhs(unit_generic_lhs, relief['crm_buyers'])\n",
    "        unit_generic_lhs = append_rbuy_lhs(unit_generic_lhs, relief['crm_provider_rhs'])\n",
    "    \n",
    "    market.link_units_to_generic_constraints(unit_generic_lhs)\n",
    "    \n",
    "    # Add generic constraints, LHS coeffients ICs\n",
    "    interconnector_generic_lhs = constraint_inputs.get_interconnector_lhs()\n",
    "    market.link_interconnectors_to_generic_constraints(\n",
    "        interconnector_generic_lhs)\n",
    "    \n",
    "    # Set the operational demand to be met by dispatch.\n",
    "    regional_demand = demand_inputs.get_operational_demand()\n",
    "    market.set_demand_constraints(regional_demand)\n",
    "        \n",
    "    return market\n",
    "\n",
    "def economic_dispatch(raw_inputs_loader, interval, sim_mode=1, select_constraint=select_constraint, relief=None):\n",
    "    \"\"\"\n",
    "    Defined modes to run economic dispatch:\n",
    "    >> 1: Pure spot market economic dispatch [Default]\n",
    "    >> 2: Spot market with constraint removed\n",
    "    >> 3: Spot market with congestion relief provider\n",
    "    \"\"\"\n",
    "    \n",
    "    if sim_mode == 2:\n",
    "        market = config_market(raw_inputs_loader,interval,add_relief_provider=False, relief=relief)\n",
    "        # Check to remove constraint set\n",
    "        if select_constraint is not None:\n",
    "            for constraint in select_constraint:\n",
    "                market.remove_generic_constraint_set(constraint)\n",
    "\n",
    "        print(\"ED Complete: Select Constraint Removed!\")\n",
    "        market.dispatch()\n",
    "\n",
    "    elif sim_mode == 3:\n",
    "        market = config_market(raw_inputs_loader,interval,add_relief_provider=True, relief=relief)\n",
    "        print(\"ED Complete: Relief Provider Added!\")\n",
    "        market.dispatch()\n",
    "        \n",
    "    else:\n",
    "        # Default must run normal spot market\n",
    "        market = config_market(raw_inputs_loader,interval,add_relief_provider=False, relief=relief)\n",
    "        print(\"ED Complete: Default!\")\n",
    "        market.dispatch()\n",
    "        \n",
    "    # Retrieve & Save market data\n",
    "    result_mv = market.get_constraint_marginal_values()\n",
    "    result_mv.insert(0,'interval',interval)\n",
    "    result_mv.insert(0,'sim_mode',sim_mode)\n",
    "    \n",
    "    result_units = market.get_unit_dispatch()\n",
    "    result_units.insert(0,'interval',interval)\n",
    "    result_units.insert(0,'sim_mode',sim_mode)\n",
    "\n",
    "    result_prices = market.get_energy_prices()\n",
    "    result_prices.insert(0,'interval',interval)\n",
    "    result_prices.insert(0,'sim_mode',sim_mode)\n",
    "\n",
    "    result_revenue = market_revenue(market._unit_info, result_prices, result_units)\n",
    "    result_revenue.insert(0,'sim_mode',sim_mode)\n",
    "        \n",
    "    return market, {'marginal_values': result_mv, 'unit_dispatch': result_units, \\\n",
    "                    'energy_prices': result_prices, 'energy_revenue': result_revenue}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### A5. Define supporting functions needed for CRM implementation and analysis\n",
    "Various additional functions are written to assist in modelling the CRM within nempy.\n",
    "\n",
    "<code>get_dispatch_difference_byconst</code> and <code>get_dispatch_difference</code> are functions which compare two nempy market objects and return the difference in dispatch between iterations.\n",
    "\n",
    "<code>get_eligible_units</code> is a function returning the units situated on the LHS of the defined selected constraints.\n",
    "\n",
    "<code>create_run_crm_market</code> is the function constructing the CRM market which is solved considering the generators and loads defined within this function.\n",
    "\n",
    "<code>format_crm_provider</code> is a function to format the crm information as output from the CRM model to be later interpreted by the economic dispatch functions in nempy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dispatch_difference_byconst(output_default, output_const_removed, show_all=False):\n",
    "    \"\"\"\n",
    "    Inputs: constraint_map, df of units for select_constraint,\n",
    "    output_default: economic dispatch output market,\n",
    "    output_const_removed: economic dispatch output market with constraint removed.\n",
    "    \"\"\"\n",
    "    constraintmap = {}\n",
    "    for constraint in select_constraint:\n",
    "        \n",
    "        # Get constraint mapping of DUIDs, coeff for select_constraint\n",
    "        constraint_lhs = market.get_constraint_mapping(constraint)['units']    \n",
    "        \n",
    "        # Get original market output for these DUIDs\n",
    "        select_units = output_default['unit_dispatch']\n",
    "        select_units = select_units[(select_units['service'] == 'energy')\\\n",
    "                        & (select_units['unit'].isin(constraint_lhs['unit'].to_list()))]\n",
    "        \n",
    "        # Get modified market output for these DUIDs\n",
    "        select_units2 = output_const_removed['unit_dispatch']\n",
    "        select_units2 = select_units2[(select_units2['service'] == 'energy')\\\n",
    "                        & (select_units2['unit'].isin(constraint_lhs['unit'].to_list()))]\n",
    "        \n",
    "        # Calculate the difference in market output\n",
    "        constraint_lhs = constraint_lhs.merge(right=select_units.loc[:,['unit','dispatch']], on='unit')\n",
    "        constraint_lhs = constraint_lhs.merge(right=select_units2.loc[:,['unit','dispatch']], on='unit', suffixes=(\"\",\"_r\"))\n",
    "        constraint_lhs['dispatch_diff'] = round(constraint_lhs['dispatch_r'] - constraint_lhs['dispatch'],2)\n",
    "        \n",
    "        if not show_all:\n",
    "            constraintmap.update({constraint: constraint_lhs.loc[:,['set','unit','dispatch_diff']]})\n",
    "        else:\n",
    "            constraintmap.update({constraint: constraint_lhs})\n",
    "    \n",
    "    return constraintmap\n",
    "\n",
    "def get_dispatch_difference(output_default, output_const_removed):\n",
    "    \"\"\"\n",
    "    Inputs: constraint_map, df of units for select_constraint,\n",
    "    output_default: economic dispatch output market,\n",
    "    output_const_removed: economic dispatch output market with constraint removed.\n",
    "    \"\"\"\n",
    "    constraintmap = {}\n",
    "    \n",
    "    # Get original market output for these DUIDs\n",
    "    all_units = output_default['unit_dispatch']\n",
    "    all_units = all_units[all_units['service'] == 'energy']\n",
    "    \n",
    "    # Get modified market output for these DUIDs\n",
    "    all_units2 = output_const_removed['unit_dispatch']\n",
    "    all_units2 = all_units2[all_units2['service'] == 'energy']\n",
    "    \n",
    "    # Calculate the difference in market output\n",
    "    result = all_units.loc[:,['unit','dispatch']]\n",
    "    result = result.merge(right=all_units2.loc[:,['unit','dispatch']], on='unit',suffixes=(\"\",\"_r\"))\n",
    "    result['dispatch_diff'] = round(result['dispatch_r'] - result['dispatch'],2)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve eligible units to participate in CRM\n",
    "def get_eligible_units(market, constraint_list):\n",
    "    constraint_map, eligible_units_map = {},{}\n",
    "    m_unitinfo = market._unit_info\n",
    "\n",
    "    for constraint in constraint_list:\n",
    "        const_units = market.get_constraint_mapping(constraint)['units']\n",
    "        constraint_map.update({constraint: const_units})\n",
    "        eligible_units_map.update({constraint: m_unitinfo[m_unitinfo['unit'].isin(const_units['unit'])]\\\n",
    "                                    .drop(['loss_factor','dispatch_type'],axis=1).reset_index(drop=True)})\n",
    "\n",
    "    return eligible_units_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_run_crm_market(eligible_units_info, cap_price, cap_provision):\n",
    "\n",
    "    new_crm = relief_market(eligible_units_info, cap_price)\n",
    "\n",
    "    \"\"\"\n",
    "    For market to clear, the storage (provider) price must be below that of the buyer (any other unit)\n",
    "    \"\"\"\n",
    "    new_crm.default_bids_offers(storage_mw=50.0, storage_offer=10.0)\n",
    "    new_crm.bid_into_crm('BERYLSF1',price=20.0,volume=87.0) \n",
    "    new_crm.bid_into_crm('MANSLR1',price=1.0,volume= 46.0) \n",
    "\n",
    "    # Optional Setting\n",
    "    #new_crm.cap_price(spotpricecap = cap_price) # set this to cap storage offer to energy price\n",
    "    new_crm.cap_relief_provision(cap_provision) # cap dispatch volume by amount of possible relief\n",
    "    \n",
    "    return new_crm.dispatch(trim_price=False) # set trim price true to cap all at energy price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_crm_provider(crm_provider):\n",
    "    crm_provider.insert(1,'region', crm_results['prices']['region'][0])\n",
    "    crm_provider.insert(2,'dispatch_type','load')\n",
    "    crm_provider.insert(2,'loss_factor',1.0)\n",
    "    crm_provider = crm_provider.rename(columns={'dispatch': 'relief_MW'})\n",
    "    crm_provider.insert(2,'default_offer',15000.0)\n",
    "    crm_provider.insert(2,'set',select_constraint[0])\n",
    "    crm_provider.insert(2,'mirror_coeff','BERYLSF1')\n",
    "    return crm_provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[Return to Index](#Home)\n",
    "<a id=\"B\"></a>\n",
    "## Section B: Model Simulation\n",
    "\n",
    "### B1. Iteration Solution\n",
    "For each dispatch interval the iteration process is considered, as commented throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs, outputs_mvs, outputs_prices, outputs_units, outputs_revenue = [],[],[],[], []\n",
    "\n",
    "for di in di_df['di_list']:\n",
    "    print(f\"=== Solving Interval {di} ===\")\n",
    "    # Get base case economic dispatch results\n",
    "    market, outputs = economic_dispatch(raw_inputs_loader, di, sim_mode=1)\n",
    "        \n",
    "    # Get economic dispatch results with constraint removed\n",
    "    market_2, outputs_2 = economic_dispatch(raw_inputs_loader, di, sim_mode=2)\n",
    "    \n",
    "    # Find the dispatch difference for applicable units (eligble amount of congestion relief)\n",
    "    dis_diff_12 = get_dispatch_difference(outputs, outputs_2)\n",
    "    dis_diff_12.insert(0,'interval',di)\n",
    "    dis_diff_12.insert(1,'id','1-2')\n",
    "        \n",
    "    # Find the units which can participate in the selected constraint for CRM\n",
    "    eligible_units_info = get_eligible_units(market, select_constraint)\n",
    "    \n",
    "    # Construct Congestion Relief Market based on a hypothetical 'willingness to pay' for each unit in the constraint.\n",
    "    # in here confine bid/offer by dispatch difference had the constraint not been binding.\n",
    "    observed_prc = outputs['energy_prices']\n",
    "    observed_prc = float(observed_prc[observed_prc['region'] == model_region]['price'])\n",
    "\n",
    "    crm_results = create_run_crm_market(eligible_units_info[select_constraint[0]], \\\n",
    "                                        cap_price=observed_prc, cap_provision=dis_diff_12)\n",
    "    \n",
    "    crm_revenue = relief_revenue(crm_results['units'],crm_results['prices'], crm_results['dispatch'])\n",
    "    \n",
    "    # Formatting the changes to be applied from CRM dispatch to the NEM energy spot market.\n",
    "    crm_data = crm_results['dispatch']\n",
    "    \n",
    "    crm_provider = crm_data[crm_data['unit'] == 'STORAGE']\n",
    "    crm_provider = format_crm_provider(crm_provider)\n",
    "\n",
    "    crm_buyer_param = crm_data[crm_data['unit'] != 'STORAGE']\n",
    "    crm_buyer_param = format_crm_buyers(crm_buyer_param)\n",
    "    \n",
    "    crm_provider_rhs = crm_data[crm_data['unit'] == 'STORAGE']\n",
    "    crm_provider_rhs = format_crm_buyers(crm_provider_rhs)\n",
    "\n",
    "    relief_data = {'new_storage': crm_provider,\n",
    "                  'crm_buyers': crm_buyer_param,\n",
    "                  'crm_provider_rhs': crm_provider_rhs}\n",
    "    \n",
    "    # Simulating the final iteration\n",
    "    # Economic Dispatch with CRM resolved.\n",
    "    market_3, outputs_3 = economic_dispatch(raw_inputs_loader, di, sim_mode=3, relief=relief_data)\n",
    "    final = outputs_3\n",
    "    final.update({'error': validate_spot_with_crm_error(di, market, market_3)})\n",
    "    \n",
    "    # Differences in dispatch simulation runs\n",
    "    dis_diff_13 = get_dispatch_difference(outputs, outputs_3)\n",
    "    dis_diff_13.insert(0,'interval',di)\n",
    "    dis_diff_13.insert(1,'id','1-3')\n",
    "    final.update({'dispatch_diff': dis_diff_12})\n",
    "    final['dispatch_diff'] = pd.concat([final['dispatch_diff'],dis_diff_13])\n",
    "    \n",
    "    # Collate CRM results\n",
    "    crm_results['prices'].insert(0,'interval',di)\n",
    "    crm_results['dispatch'].insert(0,'interval',di)\n",
    "    crm_revenue.insert(0,'interval',di)\n",
    "    final.update({'crm_prices': crm_results['prices']})\n",
    "    final.update({'crm_dispatch': crm_results['dispatch']})\n",
    "    final.update({'crm_revenue': crm_revenue})\n",
    "    \n",
    "    # Collate market results from all iterations\n",
    "    final['marginal_values'] = pd.concat([final['marginal_values'],outputs['marginal_values'],outputs_2['marginal_values']])\n",
    "    final['unit_dispatch'] = pd.concat([final['unit_dispatch'],outputs['unit_dispatch'],outputs_2['unit_dispatch']])\n",
    "    final['energy_prices'] = pd.concat([final['energy_prices'],outputs['energy_prices'],outputs_2['energy_prices']])\n",
    "    final['energy_revenue'] = pd.concat([final['energy_revenue'],outputs['energy_revenue'],outputs_2['energy_revenue']])\n",
    "    \n",
    "    # Convert the interval records from string to datetime objects\n",
    "    for key in final:\n",
    "        if 'interval' in final[key].columns:\n",
    "            final[key]['interval'] = pd.to_datetime(final[key]['interval'], format='%Y/%m/%d %H:%M:%S')\n",
    "            print(f\"updated time format for {key}\")\n",
    "    \n",
    "    # Format typeset to permit file saving\n",
    "    if '/' in di:\n",
    "        di = di.replace('/','-')\n",
    "        di = di.replace(':','-')\n",
    "    \n",
    "    # Filter to save only specified units\n",
    "    sou_list = ['BERYLSF1','BODWF1','GOONSF1','JEMALNG1','MANSLR1','MOLNGSF1','NEVERSF1','NYNGAN1','PARSF1','WELLSF1','STORAGE']\n",
    "    final['unit_dispatch'] = final['unit_dispatch'][final['unit_dispatch']['unit'].isin(sou_list)]                                                    \n",
    "    final['energy_revenue'] = final['energy_revenue'][final['energy_revenue']['unit'].isin(sou_list)]\n",
    "    final['dispatch_diff'] = final['dispatch_diff'][final['dispatch_diff']['unit'].isin(sou_list)]\n",
    "    \n",
    "    # Download Results for each dataset to csv files\n",
    "    final['marginal_values'].to_csv(os.path.join(fld_mv,f'mv_{di}.csv'),index=False)\n",
    "    final['unit_dispatch'].to_csv(os.path.join(fld_ud,f'ud_{di}.csv'),index=False)\n",
    "    final['energy_prices'].to_csv(os.path.join(fld_ep,f'ep_{di}.csv'),index=False)\n",
    "    final['energy_revenue'].to_csv(os.path.join(fld_erev,f'erev_{di}.csv'),index=False)\n",
    "    final['error'].to_csv(os.path.join(fld_err,f'err_{di}.csv'),index=False)\n",
    "    final['dispatch_diff'].to_csv(os.path.join(fld_dd,f'dd_{di}.csv'),index=False)\n",
    "    final['crm_prices'].to_csv(os.path.join(fld_cp,f'cp_{di}.csv'),index=False)\n",
    "    final['crm_dispatch'].to_csv(os.path.join(fld_cd,f'cd_{di}.csv'),index=False)\n",
    "    final['crm_revenue'].to_csv(os.path.join(fld_cr,f'cr_{di}.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[Return to Index](#Home)\n",
    "<a id=\"C\"></a>\n",
    "## Section C: Aggregating Results\n",
    "\n",
    "### C1. Reformat Results\n",
    "Having run all dispatch intervals, the results files can be aggregated to a single summary file per dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "for folder in os.listdir(fld_parent):\n",
    "    glued_data = pd.DataFrame()\n",
    "    for file in os.listdir(os.path.join(fld_parent,folder)):\n",
    "        if file.endswith('.csv'):\n",
    "            x = pd.read_csv(os.path.join(fld_parent,folder,file), low_memory=False, index_col=0)\n",
    "            glued_data = pd.concat([glued_data,x],axis=0)\n",
    "    glued_data.to_csv(os.path.join(fld_parent,f'agg_{folder}.csv'))\n",
    "    \n",
    "print(\"Finished data aggregation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A further dataset is calculated by aggregating the energy and CRM revenue components as one net revenue field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net the revenue\n",
    "crmrev = pd.read_csv(os.path.join(fld_parent,'agg_crm_revenue.csv'), low_memory=False)\n",
    "energyrev = pd.read_csv(os.path.join(fld_parent,'agg_energy_revenue.csv'), low_memory=False)\n",
    "energyrev = energyrev[energyrev['sim_mode'] == 3]\n",
    "energyrev\n",
    "\n",
    "netrev = pd.merge(left=energyrev, right=crmrev, left_on=['interval','unit'],right_on=['interval','unit'],suffixes=(\"_energy\",\"_crm\"))\n",
    "netrev['revenue_total'] = netrev['revenue_energy'] + netrev['revenue_crm']\n",
    "netrev.to_csv(os.path.join(fld_parent,f'agg_calc_net_revenue.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "constraintsenv",
   "language": "python",
   "name": "constraintsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
